#!/usr/bin/env python3
"""
æµ‹è¯•RLSFæ”¹è¿›åŠŸèƒ½çš„ç®€å•è„šæœ¬

è¯¥è„šæœ¬éªŒè¯è‡ªé€‚åº”åå·®æ ¡æ­£å’Œä¸ç¡®å®šæ€§å»ºæ¨¡æ¨¡å—æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import sys
sys.path.append('.')
sys.path.append('..')

import numpy as np
import torch

print("=" * 60)
print("RLSFæ”¹è¿›åŠŸèƒ½æµ‹è¯•")
print("=" * 60)

# æµ‹è¯•1: å¯¼å…¥æ”¹è¿›æ¨¡å—
print("\n[æµ‹è¯•1] å¯¼å…¥æ”¹è¿›æ¨¡å—...")
try:
    from Sources.algo.adaptive_bias_corrector import AdaptiveBiasCorrector, SegmentLevelBiasCorrector
    print("âœ… AdaptiveBiasCorrector å¯¼å…¥æˆåŠŸ")
    print("âœ… SegmentLevelBiasCorrector å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

try:
    from Sources.algo.uncertainty_aware_cost_estimator import UncertaintyAwareCostEstimator
    print("âœ… UncertaintyAwareCostEstimator å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

# æµ‹è¯•2: è‡ªé€‚åº”åå·®æ ¡æ­£å™¨
print("\n[æµ‹è¯•2] æµ‹è¯•è‡ªé€‚åº”åå·®æ ¡æ­£å™¨...")
try:
    corrector = AdaptiveBiasCorrector(
        window_size=100,
        initial_delta=0.1,
        adaptation_rate=0.01
    )
    
    # æ¨¡æ‹Ÿè®­ç»ƒè¿‡ç¨‹
    for i in range(10):
        training_progress = i / 10.0
        violation_rate = 0.08 - i * 0.003  # æ¨¡æ‹Ÿè¿çº¦ç‡ä¸‹é™
        
        delta = corrector.compute_adaptive_delta(
            training_progress=training_progress,
            current_violation_rate=violation_rate,
            target_violation_rate=0.05
        )
        
        # æ¨¡æ‹Ÿæˆæœ¬æ•°æ®ï¼ˆä½¿ç”¨å¼ é‡ä»¥å…¼å®¹update_statisticsæ¥å£ï¼‰
        predicted_cost = torch.tensor([np.random.rand()], dtype=torch.float32)
        true_cost = torch.tensor([np.random.rand()], dtype=torch.float32)
        corrector.update_statistics(predicted_cost, true_cost, violation_rate)

    print(f"âœ… è‡ªé€‚åº”åå·®æ ¡æ­£å™¨æµ‹è¯•é€šè¿‡")
    print(f"   æœ€ç»ˆÎ´å€¼: {corrector.delta:.4f}")
    print(f"   åå·®ä¼°è®¡: {corrector.bias_estimate:.4f}")
    
except Exception as e:
    print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# æµ‹è¯•3: ä¸ç¡®å®šæ€§æ„ŸçŸ¥æˆæœ¬ä¼°è®¡å™¨
print("\n[æµ‹è¯•3] æµ‹è¯•ä¸ç¡®å®šæ€§æ„ŸçŸ¥æˆæœ¬ä¼°è®¡å™¨...")
try:
    # åˆ›å»ºç®€å•çš„åˆ†ç±»å™¨æ¨¡æ‹Ÿ
    class MockClassifier(torch.nn.Module):
        def __init__(self):
            super().__init__()
            self.fc = torch.nn.Linear(10, 1)
        
        def forward(self, states, actions):
            # ç®€å•çš„å‰å‘ä¼ æ’­
            x = torch.cat([states, actions], dim=-1)
            return self.fc(x)
    
    # åˆ›å»ºé›†æˆåˆ†ç±»å™¨
    n_ensemble = 3
    classifiers = [MockClassifier() for _ in range(n_ensemble)]
    
    # åˆ›å»ºä¸ç¡®å®šæ€§ä¼°è®¡å™¨
    estimator = UncertaintyAwareCostEstimator(
        n_ensemble=n_ensemble,
        uncertainty_penalty=0.1,
        exploration_bonus=0.05
    )
    
    # æ¨¡æ‹Ÿé¢„æµ‹
    batch_size = 32
    state_dim = 8
    action_dim = 2
    
    states = torch.randn(batch_size, state_dim)
    actions = torch.randn(batch_size, action_dim)
    
    # è®¡ç®—é›†æˆé¢„æµ‹å’Œä¸ç¡®å®šæ€§
    mean_probs, uncertainty, individual_probs = estimator.compute_ensemble_predictions(
        classifiers, states, actions
    )
    
    print(f"âœ… ä¸ç¡®å®šæ€§æ„ŸçŸ¥æˆæœ¬ä¼°è®¡å™¨æµ‹è¯•é€šè¿‡")
    print(f"   å¹³å‡é¢„æµ‹æ¦‚ç‡: {mean_probs.mean().item():.4f}")
    print(f"   å¹³å‡ä¸ç¡®å®šæ€§: {uncertainty.mean().item():.4f}")
    print(f"   ä¸ç¡®å®šæ€§èŒƒå›´: [{uncertainty.min().item():.4f}, {uncertainty.max().item():.4f}]")
    
    # æµ‹è¯•ä¸ç¡®å®šæ€§æ„ŸçŸ¥æˆæœ¬è®¡ç®—
    costs, confidence = estimator.compute_uncertainty_aware_costs(
        mean_probs, uncertainty, class_prob=0.5
    )
    
    print(f"   å¹³å‡æˆæœ¬: {costs.mean().item():.4f}")
    print(f"   å¹³å‡ç½®ä¿¡åº¦: {confidence.mean().item():.4f}")
    
except Exception as e:
    print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# æµ‹è¯•4: Segmentçº§åˆ«åå·®æ ¡æ­£å™¨
print("\n[æµ‹è¯•4] æµ‹è¯•Segmentçº§åˆ«åå·®æ ¡æ­£å™¨...")
try:
    segment_corrector = SegmentLevelBiasCorrector(
        segment_length=100,
        confidence_threshold=0.7
    )

    # æ¨¡æ‹Ÿsegmentæ•°æ®ï¼ˆçŠ¶æ€+åŠ¨ä½œï¼‰
    segment_len = 100
    state_dim, action_dim = 8, 2
    segment_states = torch.randn(segment_len, state_dim)
    segment_actions = torch.randn(segment_len, action_dim)
    segment_label = 1  # å±é™©segment

    # ä½¿ç”¨ç®€å•çš„Mockåˆ†ç±»å™¨é›†æˆ
    classifier_ensemble = [MockClassifier() for _ in range(3)]

    improved_labels, confidence_scores = segment_corrector.improved_segment_labeling(
        segment_states, segment_actions, classifier_ensemble, segment_label
    )

    print(f"âœ… Segmentçº§åˆ«åå·®æ ¡æ­£å™¨æµ‹è¯•é€šè¿‡")
    print(f"   åŸå§‹æ ‡ç­¾: {segment_label}")
    print(f"   æ ¡æ­£åçš„æ ‡ç­¾æ•°é‡: {improved_labels.numel()}")
    print(f"   é«˜ç½®ä¿¡åº¦æ ‡ç­¾æ¯”ä¾‹: {improved_labels.float().mean().item():.2%}")

except Exception as e:
    print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# æµ‹è¯•5: é›†æˆæµ‹è¯•
print("\n[æµ‹è¯•5] é›†æˆæµ‹è¯•...")
try:
    # æ¨¡æ‹Ÿå®Œæ•´çš„è®­ç»ƒå¾ªç¯
    corrector = AdaptiveBiasCorrector(window_size=50)
    estimator = UncertaintyAwareCostEstimator(n_ensemble=3)
    
    classifiers = [MockClassifier() for _ in range(3)]
    
    for epoch in range(5):
        # æ¨¡æ‹Ÿä¸€ä¸ªepochçš„æ•°æ®
        states = torch.randn(10, 8)
        actions = torch.randn(10, 2)
        
        # è®¡ç®—ä¸ç¡®å®šæ€§æ„ŸçŸ¥çš„æˆæœ¬
        mean_probs, uncertainty, _ = estimator.compute_ensemble_predictions(
            classifiers, states, actions
        )
        costs, confidence = estimator.compute_uncertainty_aware_costs(
            mean_probs, uncertainty, class_prob=0.5
        )
        
        # åº”ç”¨åå·®æ ¡æ­£
        training_progress = epoch / 5.0
        violation_rate = 0.06 - epoch * 0.002
        delta = corrector.compute_adaptive_delta(training_progress, violation_rate)
        corrected_costs = corrector.apply_bias_correction(costs, uncertainty)
        
        # æ›´æ–°ç»Ÿè®¡
        for i in range(len(costs)):
            pc = costs[i].unsqueeze(0)
            tc = torch.tensor([np.random.rand()], dtype=torch.float32)
            corrector.update_statistics(pc, tc, violation_rate)
    
    print(f"âœ… é›†æˆæµ‹è¯•é€šè¿‡")
    print(f"   æœ€ç»ˆÎ´å€¼: {corrector.delta:.4f}")
    print(f"   æœ€ç»ˆåå·®ä¼°è®¡: {corrector.bias_estimate:.4f}")
    
except Exception as e:
    print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

print("\n" + "=" * 60)
print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼RLSFæ”¹è¿›åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
print("=" * 60)

print("\nğŸ“‹ åŠŸèƒ½æ‘˜è¦:")
print("  âœ… è‡ªé€‚åº”åå·®æ ¡æ­£ - åŠ¨æ€è°ƒæ•´Î´å‚æ•°")
print("  âœ… ä¸ç¡®å®šæ€§å»ºæ¨¡ - é›†æˆå­¦ä¹ é‡åŒ–ä¸ç¡®å®šæ€§")
print("  âœ… Segmentçº§åˆ«æ ¡æ­£ - æ”¹è¿›æ ‡ç­¾ç­–ç•¥")
print("  âœ… é›†æˆå·¥ä½œæµ - æ‰€æœ‰ç»„ä»¶ååŒå·¥ä½œ")

print("\nğŸš€ ä¸‹ä¸€æ­¥:")
print("  1. åœ¨è™šæ‹Ÿç¯å¢ƒä¸­å®‰è£…æ‰€æœ‰ä¾èµ–:")
print("     pip install torch numpy matplotlib scipy wandb safety-gymnasium")
print("  2. è¿è¡Œå®Œæ•´è®­ç»ƒ:")
print("     python Trains/train_improved_prefim.py --env_name SafetyPointCircle1-v0")
print("  3. æˆ–ä½¿ç”¨ä¸€é”®è„šæœ¬:")
print("     python run_improved_rlsf.py --mode single --env_name SafetyPointCircle1-v0")

