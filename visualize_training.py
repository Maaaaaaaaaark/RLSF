#!/usr/bin/env python3
"""
RLSFè®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–å·¥å…·

è¯¥è„šæœ¬è¯»å–è®­ç»ƒæ—¥å¿—å¹¶ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ï¼Œç”¨äºåˆ†æï¼š
1. å­¦ä¹ æ›²çº¿ï¼ˆå›æŠ¥å’Œæˆæœ¬ï¼‰
2. Î´å€¼çš„è‡ªé€‚åº”å˜åŒ–
3. ä¸ç¡®å®šæ€§ç»Ÿè®¡
4. è¿çº¦ç‡æ§åˆ¶
"""

import os
import sys
import argparse
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path

def parse_args():
    parser = argparse.ArgumentParser(description='å¯è§†åŒ–RLSFè®­ç»ƒç»“æœ')
    parser.add_argument('--log_dir', type=str, required=True,
                        help='è®­ç»ƒæ—¥å¿—ç›®å½•è·¯å¾„')
    parser.add_argument('--output_dir', type=str, default='./visualizations',
                        help='è¾“å‡ºå›¾è¡¨ä¿å­˜ç›®å½•')
    parser.add_argument('--compare_baseline', action='store_true',
                        help='æ˜¯å¦ä¸åŸºçº¿å¯¹æ¯”')
    parser.add_argument('--baseline_dir', type=str, default=None,
                        help='åŸºçº¿æ—¥å¿—ç›®å½•è·¯å¾„')
    return parser.parse_args()

def load_training_log(log_dir):
    """åŠ è½½è®­ç»ƒæ—¥å¿—æ•°æ®"""
    data = {}
    
    # è¯»å–å›æŠ¥å’Œæˆæœ¬
    return_file = os.path.join(log_dir, 'eval_return.txt')
    cost_file = os.path.join(log_dir, 'eval_cost.txt')
    
    if os.path.exists(return_file):
        with open(return_file, 'r') as f:
            data['returns'] = [float(line.strip()) for line in f if line.strip()]
    
    if os.path.exists(cost_file):
        with open(cost_file, 'r') as f:
            data['costs'] = [float(line.strip()) for line in f if line.strip()]
    
    # å°è¯•è¯»å–æ”¹è¿›ç‰ˆç‰¹æœ‰çš„æŒ‡æ ‡
    delta_file = os.path.join(log_dir, 'delta_values.txt')
    uncertainty_file = os.path.join(log_dir, 'uncertainty_stats.txt')
    
    if os.path.exists(delta_file):
        with open(delta_file, 'r') as f:
            data['deltas'] = [float(line.strip()) for line in f if line.strip()]
    
    if os.path.exists(uncertainty_file):
        with open(uncertainty_file, 'r') as f:
            data['uncertainties'] = [float(line.strip()) for line in f if line.strip()]
    
    return data

def plot_learning_curves(data, baseline_data=None, output_dir='./visualizations'):
    """ç»˜åˆ¶å­¦ä¹ æ›²çº¿"""
    fig, axes = plt.subplots(2, 1, figsize=(12, 8))
    
    # å›æŠ¥æ›²çº¿
    if 'returns' in data:
        steps = np.arange(len(data['returns']))
        axes[0].plot(steps, data['returns'], label='Improved RLSF', linewidth=2, alpha=0.8)
        
        if baseline_data and 'returns' in baseline_data:
            baseline_steps = np.arange(len(baseline_data['returns']))
            axes[0].plot(baseline_steps, baseline_data['returns'], 
                        label='Baseline RLSF', linewidth=2, alpha=0.8, linestyle='--')
        
        axes[0].set_xlabel('Evaluation Step', fontsize=12)
        axes[0].set_ylabel('Average Return', fontsize=12)
        axes[0].set_title('Learning Curve - Return', fontsize=14, fontweight='bold')
        axes[0].legend(fontsize=10)
        axes[0].grid(True, alpha=0.3)
    
    # æˆæœ¬æ›²çº¿
    if 'costs' in data:
        steps = np.arange(len(data['costs']))
        axes[1].plot(steps, data['costs'], label='Improved RLSF', 
                    linewidth=2, alpha=0.8, color='red')
        
        if baseline_data and 'costs' in baseline_data:
            baseline_steps = np.arange(len(baseline_data['costs']))
            axes[1].plot(baseline_steps, baseline_data['costs'], 
                        label='Baseline RLSF', linewidth=2, alpha=0.8, 
                        linestyle='--', color='orange')
        
        # æ·»åŠ æˆæœ¬é˜ˆå€¼çº¿
        axes[1].axhline(y=25, color='black', linestyle=':', 
                       label='Cost Limit', linewidth=1.5)
        
        axes[1].set_xlabel('Evaluation Step', fontsize=12)
        axes[1].set_ylabel('Average Cost', fontsize=12)
        axes[1].set_title('Learning Curve - Cost', fontsize=14, fontweight='bold')
        axes[1].legend(fontsize=10)
        axes[1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    os.makedirs(output_dir, exist_ok=True)
    output_path = os.path.join(output_dir, 'learning_curves.png')
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"âœ… å­¦ä¹ æ›²çº¿å·²ä¿å­˜åˆ°: {output_path}")
    plt.close()

def plot_delta_dynamics(data, output_dir='./visualizations'):
    """ç»˜åˆ¶Î´å€¼åŠ¨æ€å˜åŒ–"""
    if 'deltas' not in data:
        print("âš ï¸  æœªæ‰¾åˆ°Î´å€¼æ•°æ®ï¼Œè·³è¿‡ç»˜åˆ¶")
        return
    
    fig, ax = plt.subplots(figsize=(12, 6))
    
    steps = np.arange(len(data['deltas']))
    deltas = data['deltas']
    
    # ç»˜åˆ¶Î´å€¼æ›²çº¿
    ax.plot(steps, deltas, linewidth=2, color='blue', alpha=0.8, label='Î´ value')
    
    # æ·»åŠ ç§»åŠ¨å¹³å‡çº¿
    window_size = min(50, len(deltas) // 10)
    if window_size > 1:
        moving_avg = np.convolve(deltas, np.ones(window_size)/window_size, mode='valid')
        avg_steps = np.arange(window_size-1, len(deltas))
        ax.plot(avg_steps, moving_avg, linewidth=2, color='red', 
               alpha=0.6, label=f'Moving Average (window={window_size})')
    
    # æ·»åŠ å‚è€ƒçº¿
    ax.axhline(y=0.1, color='green', linestyle='--', 
              label='Initial Î´', linewidth=1.5, alpha=0.5)
    
    ax.set_xlabel('Training Step', fontsize=12)
    ax.set_ylabel('Î´ Value', fontsize=12)
    ax.set_title('Adaptive Bias Correction - Î´ Dynamics', 
                fontsize=14, fontweight='bold')
    ax.legend(fontsize=10)
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    output_path = os.path.join(output_dir, 'delta_dynamics.png')
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"âœ… Î´å€¼åŠ¨æ€å›¾å·²ä¿å­˜åˆ°: {output_path}")
    plt.close()

def plot_uncertainty_stats(data, output_dir='./visualizations'):
    """ç»˜åˆ¶ä¸ç¡®å®šæ€§ç»Ÿè®¡"""
    if 'uncertainties' not in data:
        print("âš ï¸  æœªæ‰¾åˆ°ä¸ç¡®å®šæ€§æ•°æ®ï¼Œè·³è¿‡ç»˜åˆ¶")
        return
    
    fig, axes = plt.subplots(2, 1, figsize=(12, 8))
    
    steps = np.arange(len(data['uncertainties']))
    uncertainties = data['uncertainties']
    
    # ä¸ç¡®å®šæ€§éšæ—¶é—´å˜åŒ–
    axes[0].plot(steps, uncertainties, linewidth=2, color='purple', alpha=0.8)
    axes[0].set_xlabel('Training Step', fontsize=12)
    axes[0].set_ylabel('Mean Uncertainty', fontsize=12)
    axes[0].set_title('Uncertainty Evolution', fontsize=14, fontweight='bold')
    axes[0].grid(True, alpha=0.3)
    
    # ä¸ç¡®å®šæ€§åˆ†å¸ƒï¼ˆç›´æ–¹å›¾ï¼‰
    axes[1].hist(uncertainties, bins=50, color='purple', alpha=0.7, edgecolor='black')
    axes[1].axvline(x=np.mean(uncertainties), color='red', linestyle='--', 
                   linewidth=2, label=f'Mean: {np.mean(uncertainties):.4f}')
    axes[1].axvline(x=np.median(uncertainties), color='green', linestyle='--', 
                   linewidth=2, label=f'Median: {np.median(uncertainties):.4f}')
    axes[1].set_xlabel('Uncertainty Value', fontsize=12)
    axes[1].set_ylabel('Frequency', fontsize=12)
    axes[1].set_title('Uncertainty Distribution', fontsize=14, fontweight='bold')
    axes[1].legend(fontsize=10)
    axes[1].grid(True, alpha=0.3, axis='y')
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    output_path = os.path.join(output_dir, 'uncertainty_stats.png')
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"âœ… ä¸ç¡®å®šæ€§ç»Ÿè®¡å›¾å·²ä¿å­˜åˆ°: {output_path}")
    plt.close()

def plot_performance_comparison(data, baseline_data, output_dir='./visualizations'):
    """ç»˜åˆ¶æ€§èƒ½å¯¹æ¯”å›¾"""
    if not baseline_data:
        print("âš ï¸  æœªæä¾›åŸºçº¿æ•°æ®ï¼Œè·³è¿‡å¯¹æ¯”å›¾")
        return
    
    fig, ax = plt.subplots(figsize=(10, 6))
    
    # è®¡ç®—æœ€ç»ˆæ€§èƒ½æŒ‡æ ‡
    metrics = ['Final Return', 'Final Cost', 'Convergence Speed']
    
    improved_values = []
    baseline_values = []
    
    # æœ€ç»ˆå›æŠ¥
    if 'returns' in data and 'returns' in baseline_data:
        improved_final_return = np.mean(data['returns'][-10:])
        baseline_final_return = np.mean(baseline_data['returns'][-10:])
        improved_values.append(improved_final_return)
        baseline_values.append(baseline_final_return)
    
    # æœ€ç»ˆæˆæœ¬
    if 'costs' in data and 'costs' in baseline_data:
        improved_final_cost = np.mean(data['costs'][-10:])
        baseline_final_cost = np.mean(baseline_data['costs'][-10:])
        # æˆæœ¬è¶Šä½è¶Šå¥½ï¼Œæ‰€ä»¥å–è´Ÿå€¼ç”¨äºå¯è§†åŒ–
        improved_values.append(-improved_final_cost)
        baseline_values.append(-baseline_final_cost)
    
    # æ”¶æ•›é€Ÿåº¦ï¼ˆè¾¾åˆ°é˜ˆå€¼æ‰€éœ€æ­¥æ•°çš„å€’æ•°ï¼‰
    if 'returns' in data and 'returns' in baseline_data:
        threshold = np.mean(baseline_data['returns'][-10:]) * 0.9
        
        improved_convergence = next((i for i, r in enumerate(data['returns']) 
                                    if r >= threshold), len(data['returns']))
        baseline_convergence = next((i for i, r in enumerate(baseline_data['returns']) 
                                    if r >= threshold), len(baseline_data['returns']))
        
        # æ”¶æ•›è¶Šå¿«è¶Šå¥½ï¼Œæ‰€ä»¥å–å€’æ•°
        improved_values.append(1000.0 / max(improved_convergence, 1))
        baseline_values.append(1000.0 / max(baseline_convergence, 1))
    
    # ç»˜åˆ¶å¯¹æ¯”æŸ±çŠ¶å›¾
    x = np.arange(len(metrics))
    width = 0.35
    
    bars1 = ax.bar(x - width/2, improved_values, width, label='Improved RLSF', 
                   color='blue', alpha=0.7)
    bars2 = ax.bar(x + width/2, baseline_values, width, label='Baseline RLSF', 
                   color='orange', alpha=0.7)
    
    ax.set_xlabel('Metrics', fontsize=12)
    ax.set_ylabel('Value (Normalized)', fontsize=12)
    ax.set_title('Performance Comparison', fontsize=14, fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels(metrics)
    ax.legend(fontsize=10)
    ax.grid(True, alpha=0.3, axis='y')
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bars in [bars1, bars2]:
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{height:.2f}',
                   ha='center', va='bottom', fontsize=9)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    output_path = os.path.join(output_dir, 'performance_comparison.png')
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"âœ… æ€§èƒ½å¯¹æ¯”å›¾å·²ä¿å­˜åˆ°: {output_path}")
    plt.close()

def generate_summary_report(data, baseline_data=None, output_dir='./visualizations'):
    """ç”Ÿæˆæ–‡æœ¬æ‘˜è¦æŠ¥å‘Š"""
    report_lines = []
    report_lines.append("=" * 60)
    report_lines.append("RLSFè®­ç»ƒç»“æœæ‘˜è¦æŠ¥å‘Š")
    report_lines.append("=" * 60)
    report_lines.append("")
    
    # æ”¹è¿›ç‰ˆæ€§èƒ½
    report_lines.append("ã€æ”¹è¿›ç‰ˆRLSFã€‘")
    if 'returns' in data:
        final_return = np.mean(data['returns'][-10:])
        return_std = np.std(data['returns'][-10:])
        report_lines.append(f"  æœ€ç»ˆå›æŠ¥: {final_return:.2f} Â± {return_std:.2f}")
    
    if 'costs' in data:
        final_cost = np.mean(data['costs'][-10:])
        cost_std = np.std(data['costs'][-10:])
        report_lines.append(f"  æœ€ç»ˆæˆæœ¬: {final_cost:.2f} Â± {cost_std:.2f}")
    
    if 'deltas' in data:
        final_delta = np.mean(data['deltas'][-100:])
        delta_std = np.std(data['deltas'][-100:])
        report_lines.append(f"  æœ€ç»ˆÎ´å€¼: {final_delta:.4f} Â± {delta_std:.4f}")
    
    if 'uncertainties' in data:
        mean_uncertainty = np.mean(data['uncertainties'])
        report_lines.append(f"  å¹³å‡ä¸ç¡®å®šæ€§: {mean_uncertainty:.4f}")
    
    report_lines.append("")
    
    # åŸºçº¿æ€§èƒ½
    if baseline_data:
        report_lines.append("ã€åŸºçº¿RLSFã€‘")
        if 'returns' in baseline_data:
            baseline_return = np.mean(baseline_data['returns'][-10:])
            baseline_return_std = np.std(baseline_data['returns'][-10:])
            report_lines.append(f"  æœ€ç»ˆå›æŠ¥: {baseline_return:.2f} Â± {baseline_return_std:.2f}")
        
        if 'costs' in baseline_data:
            baseline_cost = np.mean(baseline_data['costs'][-10:])
            baseline_cost_std = np.std(baseline_data['costs'][-10:])
            report_lines.append(f"  æœ€ç»ˆæˆæœ¬: {baseline_cost:.2f} Â± {baseline_cost_std:.2f}")
        
        report_lines.append("")
        
        # æ”¹è¿›å¹…åº¦
        report_lines.append("ã€æ”¹è¿›å¹…åº¦ã€‘")
        if 'returns' in data and 'returns' in baseline_data:
            improvement = ((final_return - baseline_return) / abs(baseline_return)) * 100
            report_lines.append(f"  å›æŠ¥æå‡: {improvement:+.2f}%")
        
        if 'costs' in data and 'costs' in baseline_data:
            cost_reduction = ((baseline_cost - final_cost) / baseline_cost) * 100
            report_lines.append(f"  æˆæœ¬é™ä½: {cost_reduction:+.2f}%")
    
    report_lines.append("")
    report_lines.append("=" * 60)
    
    # ä¿å­˜æŠ¥å‘Š
    report_path = os.path.join(output_dir, 'summary_report.txt')
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write('\n'.join(report_lines))
    
    # æ‰“å°åˆ°æ§åˆ¶å°
    print('\n'.join(report_lines))
    print(f"\nâœ… æ‘˜è¦æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")

def main():
    args = parse_args()
    
    print("=" * 60)
    print("RLSFè®­ç»ƒç»“æœå¯è§†åŒ–å·¥å…·")
    print("=" * 60)
    
    # åŠ è½½æ•°æ®
    print(f"\nğŸ“‚ åŠ è½½è®­ç»ƒæ—¥å¿—: {args.log_dir}")
    data = load_training_log(args.log_dir)
    
    baseline_data = None
    if args.compare_baseline and args.baseline_dir:
        print(f"ğŸ“‚ åŠ è½½åŸºçº¿æ—¥å¿—: {args.baseline_dir}")
        baseline_data = load_training_log(args.baseline_dir)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    
    # ç”Ÿæˆå¯è§†åŒ–
    print(f"\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    plot_learning_curves(data, baseline_data, args.output_dir)
    plot_delta_dynamics(data, args.output_dir)
    plot_uncertainty_stats(data, args.output_dir)
    
    if baseline_data:
        plot_performance_comparison(data, baseline_data, args.output_dir)
    
    # ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
    print(f"\nğŸ“ ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š...")
    generate_summary_report(data, baseline_data, args.output_dir)
    
    print(f"\nâœ… æ‰€æœ‰å¯è§†åŒ–å·²å®Œæˆï¼è¾“å‡ºç›®å½•: {args.output_dir}")

if __name__ == '__main__':
    main()

