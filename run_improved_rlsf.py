#!/usr/bin/env python3
"""
RLSFæ”¹è¿›ç®—æ³•ä¸€é”®è¿è¡Œè„šæœ¬

è¯¥è„šæœ¬æä¾›äº†ç®€å•çš„æ¥å£æ¥è¿è¡Œæ”¹è¿›ç‰ˆRLSFç®—æ³•ï¼ŒåŒ…æ‹¬ï¼š
1. å•æ¬¡å®éªŒè¿è¡Œ
2. æ¶ˆèç ”ç©¶
3. åŸºå‡†æµ‹è¯•
4. ç»“æœåˆ†æ
"""

import os
import sys
import argparse
import subprocess
import json
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(__file__))

def run_single_experiment(args):
    """è¿è¡Œå•æ¬¡å®éªŒ"""
    print("ğŸš€ Running Single RLSF Experiment")
    print(f"Environment: {args.env_name}")
    print(f"Improvements: Bias Correction={args.enable_bias_correction}, "
          f"Uncertainty Modeling={args.enable_uncertainty_modeling}")

    # ä½¿ç”¨æ”¹è¿›ç‰ˆè®­ç»ƒè„šæœ¬
    cmd = [
        'python', 'Trains/train_improved_prefim.py',
        f'--env_name={args.env_name}',
        f'--seed={args.seed}',
        f'--num_training_step={args.num_training_step}',
        f'--wandb_log={args.wandb_log}',
        f'--n_ensemble={args.n_ensemble}'
    ]

    # æ·»åŠ å…¶ä»–å‚æ•°
    if args.max_episode_length:
        cmd.append(f'--max_episode_length={args.max_episode_length}')
    if args.segment_length:
        cmd.append(f'--segment_length={args.segment_length}')

    try:
        print("Starting training...")
        result = subprocess.run(cmd, check=True)
        print("âœ… Training completed successfully!")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ Training failed with error: {e}")
        return False

def run_ablation_study(args):
    """è¿è¡Œæ¶ˆèç ”ç©¶"""
    print("ğŸ§ª Running Ablation Study")
    
    cmd = [
        'python', 'Scripts/run_ablation_study.py',
        '--environments'] + args.environments + [
        '--seeds'] + [str(s) for s in args.seeds] + [
        f'--output_dir={args.output_dir}',
        f'--num_training_step={args.num_training_step}'
    ]
    
    try:
        print("Starting ablation study...")
        result = subprocess.run(cmd, check=True)
        print("âœ… Ablation study completed successfully!")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ Ablation study failed with error: {e}")
        return False

def run_benchmark(args):
    """è¿è¡ŒåŸºå‡†æµ‹è¯•"""
    print("ğŸ“Š Running Performance Benchmark")
    
    # è¿™é‡Œéœ€è¦å®ç°åŸºå‡†æµ‹è¯•é€»è¾‘
    # å‡è®¾å·²æœ‰åŸºçº¿ç»“æœå’Œæ”¹è¿›ç»“æœ
    
    try:
        from Sources.utils.evaluation_metrics import PerformanceBenchmark
        
        benchmark = PerformanceBenchmark(
            baseline_results_dir=args.baseline_dir,
            improved_results_dir=args.improved_dir
        )
        
        results = benchmark.run_benchmark()
        benchmark.generate_benchmark_report(
            output_file=os.path.join(args.output_dir, 'benchmark_report.md')
        )
        
        print("âœ… Benchmark completed successfully!")
        return True
        
    except Exception as e:
        print(f"âŒ Benchmark failed with error: {e}")
        return False

def analyze_results(args):
    """åˆ†æå®éªŒç»“æœ"""
    print("ğŸ“ˆ Analyzing Results")
    
    try:
        from Sources.utils.evaluation_metrics import RLSFEvaluationMetrics
        
        # åŠ è½½ç»“æœå¹¶ç”Ÿæˆåˆ†ææŠ¥å‘Š
        evaluator = RLSFEvaluationMetrics(save_dir=args.output_dir)
        
        # è¿™é‡Œéœ€è¦åŠ è½½å®é™…çš„å®éªŒæ•°æ®
        # ç®€åŒ–ç‰ˆæœ¬ï¼šç›´æ¥ç”Ÿæˆç¤ºä¾‹æŠ¥å‘Š
        
        print("âœ… Results analysis completed!")
        return True
        
    except Exception as e:
        print(f"âŒ Results analysis failed with error: {e}")
        return False

def setup_environment():
    """è®¾ç½®è¿è¡Œç¯å¢ƒ"""
    print("ğŸ”§ Setting up environment...")
    
    # æ£€æŸ¥å¿…è¦çš„ä¾èµ–
    required_packages = ['torch', 'numpy', 'matplotlib']
    missing_packages = []
    
    for package in required_packages:
        try:
            __import__(package)
        except ImportError:
            missing_packages.append(package)
    
    if missing_packages:
        print(f"âŒ Missing required packages: {missing_packages}")
        print("Please install them using: pip install " + " ".join(missing_packages))
        return False
    
    # æ£€æŸ¥CUDAå¯ç”¨æ€§
    try:
        import torch
        if torch.cuda.is_available():
            print(f"âœ… CUDA available: {torch.cuda.get_device_name(0)}")
        else:
            print("âš ï¸  CUDA not available, using CPU")
    except:
        pass
    
    print("âœ… Environment setup completed!")
    return True

def main():
    parser = argparse.ArgumentParser(description='RLSF Improved Algorithm Runner')
    
    # é€šç”¨å‚æ•°
    parser.add_argument('--mode', type=str, choices=['single', 'ablation', 'benchmark', 'analyze'],
                       default='single', help='Running mode')
    parser.add_argument('--output_dir', type=str, default='./results',
                       help='Output directory for results')
    
    # å•æ¬¡å®éªŒå‚æ•°
    parser.add_argument('--env_name', type=str, default='SafetyPointCircle1-v0',
                       help='Environment name')
    parser.add_argument('--seed', type=int, default=0, help='Random seed')
    parser.add_argument('--num_training_step', type=int, default=100000,
                       help='Number of training steps')
    parser.add_argument('--max_episode_length', type=int, default=500,
                       help='Maximum episode length')
    parser.add_argument('--segment_length', type=int, default=500,
                       help='Segment length for feedback')
    parser.add_argument('--n_ensemble', type=int, default=3,
                       help='Number of ensemble models')
    
    # æ”¹è¿›åŠŸèƒ½å¼€å…³
    parser.add_argument('--enable_bias_correction', type=str, default='True',
                       help='Enable adaptive bias correction')
    parser.add_argument('--enable_uncertainty_modeling', type=str, default='True',
                       help='Enable uncertainty-aware cost estimation')
    parser.add_argument('--enable_improved_labeling', type=str, default='True',
                       help='Enable improved segment labeling')
    
    # å®éªŒé…ç½®
    parser.add_argument('--experiment_name', type=str, default='improved_rlsf',
                       help='Experiment name')
    parser.add_argument('--wandb_log', type=str, default='True',
                       help='Enable Weights & Biases logging')
    
    # æ¶ˆèç ”ç©¶å‚æ•°
    parser.add_argument('--environments', nargs='+',
                       default=['SafetyPointCircle1-v0', 'SafetyCarCircle1-v0'],
                       help='List of environments for ablation study')
    parser.add_argument('--seeds', nargs='+', type=int, default=[0, 1, 2],
                       help='List of seeds for ablation study')
    
    # åŸºå‡†æµ‹è¯•å‚æ•°
    parser.add_argument('--baseline_dir', type=str, default='./baseline_results',
                       help='Baseline results directory')
    parser.add_argument('--improved_dir', type=str, default='./improved_results',
                       help='Improved results directory')
    
    args = parser.parse_args()
    
    # è®¾ç½®ç¯å¢ƒ
    if not setup_environment():
        return 1
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    
    # è®°å½•è¿è¡Œé…ç½®
    config_file = os.path.join(args.output_dir, 'run_config.json')
    with open(config_file, 'w') as f:
        json.dump(vars(args), f, indent=2)
    
    print(f"\n{'='*60}")
    print(f"RLSF IMPROVED ALGORITHM RUNNER")
    print(f"Mode: {args.mode.upper()}")
    print(f"Output Directory: {args.output_dir}")
    print(f"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'='*60}\n")
    
    # æ ¹æ®æ¨¡å¼è¿è¡Œç›¸åº”åŠŸèƒ½
    success = False
    
    if args.mode == 'single':
        success = run_single_experiment(args)
    elif args.mode == 'ablation':
        success = run_ablation_study(args)
    elif args.mode == 'benchmark':
        success = run_benchmark(args)
    elif args.mode == 'analyze':
        success = analyze_results(args)
    else:
        print(f"âŒ Unknown mode: {args.mode}")
        return 1
    
    if success:
        print(f"\nğŸ‰ {args.mode.capitalize()} completed successfully!")
        print(f"Results saved to: {args.output_dir}")
        return 0
    else:
        print(f"\nğŸ’¥ {args.mode.capitalize()} failed!")
        return 1

if __name__ == "__main__":
    exit(main())
